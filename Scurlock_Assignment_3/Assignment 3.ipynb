{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Customer Churn\n",
    "One of the important applications of classification techniques in marketing analytics lies in predicting whether individual customers will defect to a competitor over a fixed time period (e.g. over the next year). Your goal is to build the best model possible to predict churn. In this problem you will use the “churn_data.csv” file to make these kinds of predictions, and you will implement a Jupyter notebook to accomplish this. Please make sure your Jupyter notebook addresses the questions with appropriate discussion (i.e. you will want to include appropriate discussion around your code).\n",
    "\n",
    "1) Load the “churn_data.csv” dataset into Python. What is the response variable, and what are the predictor variables?\n",
    "\n",
    "2) What data transforms are necessary to perform on this data and why?\n",
    "\n",
    "3) What modeling approaches did you use and why? Describe your model development process, including the different models tried, feature selection methods, and the different transformation techniques you employed. (**NOTE: Please do not forget to use your KNN algorithm from part 1 as one of your methods).**\n",
    "\n",
    "4) Which error metrics did you use to assess performance and why? What kind of performance did you obtain on the different models you built?\n",
    "\n",
    "5) Construct the best (i.e. least-error) possible model on this data set. What are the predictors used?\n",
    "\n",
    "6) Load the dataset “churn_validation.csv” into a new data frame and recode as necessary. Predict the outcomes for each of the customers and compare to the actual. What are the error rates you get based on your selected metrics?\n",
    "\n",
    "7) Consider the best model you built for this problem. Is it a good model that can reliably be used for prediction? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Education</th>\n",
       "      <th>Calls</th>\n",
       "      <th>Visits</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123251</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>Lower</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188922</td>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>Lower</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145322</td>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "      <td>Lower</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153729</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>Lower</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103976</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>Lower</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustID  Gender  Age Income  FamilySize  Education  Calls  Visits Churn\n",
       "0  123251    Male   34  Lower           4         16     14       5   Yes\n",
       "1  188922    Male   20  Lower           5         14     49       1    No\n",
       "2  145322  Female   30  Lower           4         20     19       4   Yes\n",
       "3  153729  Female   46  Lower           4         14     15       4   Yes\n",
       "4  103976  Female   23  Lower           4         16     18       0    No"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import knn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "data_train = pd.read_csv('churn_data.csv')\n",
    "data_test = pd.read_csv('churn_validation.csv')\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see looking at the churn dataset every customer has a set of discriptive variables such as gender, age, income, etc., a customer ID variable, and whether or not they stayed a customer as indicated by the Churn column. So the goal is to use the discriptive vairables of the customer to predict the Churn. \n",
    "However, before creating a classifier for the data first the data needs to be transformed into a usable state. First the 'CustID' columns need to be dropped since it has no relation to the target variable and only adds noise to the model. Then the categorical variables 'Gender' and 'Income' need to be one-hot encoded so that all of the vairables are numerical. Next, I normalized the data so it was all on a scale from 0 to 1 to help make sure that all of the variables were weighted equally in the predcting models. Lastly, I converted the Yes and No variables in the Churn column to 1s and 0s respectively. This made it easier to impliment the predicting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Drop Uniqe ID Variable\n",
    "data_train = data_train.drop(labels=['CustID'], axis = 1)\n",
    "data_test = data_test.drop(labels=['CustID'], axis = 1)\n",
    "\n",
    "#One Hot Encode Categorical Variables\n",
    "data_train = pd.get_dummies(data_train, columns=['Gender','Income'])\n",
    "data_test = pd.get_dummies(data_test, columns=['Gender','Income'])\n",
    "\n",
    "#Convert Yes and No value to 1 and 0 [yes = 1 and no = 0]\n",
    "data_train = data_train.replace(to_replace='Yes', value=1)\n",
    "data_train = data_train.replace(to_replace = 'No', value=0)\n",
    "\n",
    "data_test = data_test.replace(to_replace='Yes', value=1)\n",
    "data_test = data_test.replace(to_replace = 'No', value=0)\n",
    "              \n",
    "features = list(data_train)\n",
    "features.remove('Churn')\n",
    "\n",
    "data_x, data_y = data_train[features], data_train['Churn']\n",
    "\n",
    "# Convert all data so it is in a scale from 0 to 1\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data_x = min_max_scaler.fit_transform(data_x)\n",
    "data_x_testing = min_max_scaler.transform(data_test[features])\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size = 0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age and Churn have a correlation of -0.19812588642853068\n",
      "FamilySize and Churn have a correlation of -0.2641910054578153\n",
      "Education and Churn have a correlation of -0.04254356298115171\n",
      "Calls and Churn have a correlation of 0.2252229177533687\n",
      "Visits and Churn have a correlation of 0.01943917038501359\n",
      "Churn and Churn have a correlation of -0.011953709238683665\n",
      "Gender_Female and Churn have a correlation of 0.2430949469092278\n",
      "Gender_Male and Churn have a correlation of -0.2430949469092278\n",
      "Income_Lower and Churn have a correlation of -0.06262242910851495\n",
      "Income_Upper and Churn have a correlation of 0.06262242910851495\n"
     ]
    }
   ],
   "source": [
    "# To try to better understand the data I tested the correlation between the churn and the other variables which \n",
    "#showed to have insignificant correlation\n",
    "for i in list(data_test):\n",
    "    print(i,'and Churn have a correlation of',data_test[i].corr(data_train['Churn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Modeling Approaches\n",
    "\n",
    "While trying to find the best model for the data I decided to try three different models; naive bayse, random forest, and a knn classifier. Then for each model I tested to see which conditions created the best model. I decided against using support vector machines because that method works best with larger sets of data and with less than 10 variables I thought it wouldn't perform well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Naive Bayse - Gaussian\n",
    "### Testing the model with training data\n",
    "As we can see the Naive bayse method doesn't work very well. After experimenting with the different methods Gaussian performed the best, however, the accuracy is only about 69% which is not very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6923076923076923\n",
      "Precision: 0.8\n",
      "Recall: 0.5714285714285714\n",
      "F1: 0.6666666666666666\n",
      "ROC AUC: 0.7023809523809523\n",
      "Confusion Matric: \n",
      "[[15  3]\n",
      " [ 9 12]]\n"
     ]
    }
   ],
   "source": [
    "# Build and evaluate the model.\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "#nb = naive_bayes.BernoulliNB()\n",
    "#nb = naive_bayes.MultinomialNB()\n",
    "nb = naive_bayes.GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_hat = nb.predict(x_test)\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "print('Precision: ' + str(precision_score(y_test, y_hat)))\n",
    "print('Recall: ' + str(recall_score(y_test, y_hat)))\n",
    "print('F1: ' + str(f1_score(y_test, y_hat)))\n",
    "print('ROC AUC: ' + str(roc_auc_score(y_test, y_hat)))\n",
    "print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Random Forest\n",
    "It is difficult to say which combination of esimators and depth is the best. So using the combinations of depth and estimators that generate an accuracy of greater than 83% I plan to see how they fair on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Evaluating model: n_estimators =5, max_depth = 5 ------\n",
      "Accuracy: 0.8461538461538461\n",
      "Avg. F1 (Micro): 0.8461538461538461\n",
      "Avg. F1 (Macro): 0.8460526315789474\n",
      "Avg. F1 (Weighted): 0.8457489878542509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85        22\n",
      "           1       0.76      0.94      0.84        17\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.85      0.86      0.85        39\n",
      "weighted avg       0.86      0.85      0.85        39\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 5 16]]\n",
      "------ Evaluating model: n_estimators =10, max_depth = 4 ------\n",
      "Accuracy: 0.8461538461538461\n",
      "Avg. F1 (Micro): 0.8461538461538461\n",
      "Avg. F1 (Macro): 0.8452380952380952\n",
      "Avg. F1 (Weighted): 0.8461538461538461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        18\n",
      "           1       0.86      0.86      0.86        21\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.85      0.85      0.85        39\n",
      "weighted avg       0.85      0.85      0.85        39\n",
      "\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [ 3 18]]\n",
      "------ Evaluating model: n_estimators =80, max_depth = 2 ------\n",
      "Accuracy: 0.8461538461538461\n",
      "Avg. F1 (Micro): 0.8461538461538461\n",
      "Avg. F1 (Macro): 0.8452380952380952\n",
      "Avg. F1 (Weighted): 0.8461538461538461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        18\n",
      "           1       0.86      0.86      0.86        21\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.85      0.85      0.85        39\n",
      "weighted avg       0.85      0.85      0.85        39\n",
      "\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [ 3 18]]\n",
      "------ Evaluating model: n_estimators =80, max_depth = 3 ------\n",
      "Accuracy: 0.8461538461538461\n",
      "Avg. F1 (Micro): 0.8461538461538461\n",
      "Avg. F1 (Macro): 0.8460526315789474\n",
      "Avg. F1 (Weighted): 0.8457489878542509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85        22\n",
      "           1       0.76      0.94      0.84        17\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.85      0.86      0.85        39\n",
      "weighted avg       0.86      0.85      0.85        39\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 5 16]]\n",
      "------ Evaluating model: n_estimators =80, max_depth = 4 ------\n",
      "Accuracy: 0.8461538461538461\n",
      "Avg. F1 (Micro): 0.8461538461538461\n",
      "Avg. F1 (Macro): 0.8460526315789474\n",
      "Avg. F1 (Weighted): 0.8457489878542509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85        22\n",
      "           1       0.76      0.94      0.84        17\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.85      0.86      0.85        39\n",
      "weighted avg       0.86      0.85      0.85        39\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 5 16]]\n",
      "------ Evaluating model: n_estimators =80, max_depth = 5 ------\n",
      "Accuracy: 0.8461538461538461\n",
      "Avg. F1 (Micro): 0.8461538461538461\n",
      "Avg. F1 (Macro): 0.8460526315789474\n",
      "Avg. F1 (Weighted): 0.8457489878542509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85        22\n",
      "           1       0.76      0.94      0.84        17\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.85      0.86      0.85        39\n",
      "weighted avg       0.86      0.85      0.85        39\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 5 16]]\n",
      "------ Evaluating model: n_estimators =80, max_depth = 6 ------\n",
      "Accuracy: 0.8461538461538461\n",
      "Avg. F1 (Micro): 0.8461538461538461\n",
      "Avg. F1 (Macro): 0.8452380952380951\n",
      "Avg. F1 (Weighted): 0.8443223443223443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        24\n",
      "           1       0.71      1.00      0.83        15\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.86      0.88      0.85        39\n",
      "weighted avg       0.89      0.85      0.85        39\n",
      "\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 6 15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from error_metrics import *\n",
    "\n",
    "# Builds a sequence of Random Forest models for different n_est and depth values\n",
    "n_ests = [5, 10, 50, 80]\n",
    "depths = [2, 3, 4, 5, 6]\n",
    "\n",
    "# Creates a list of tuples containing the n-est and depth values that perform well (n-est, depth)\n",
    "good_forest = []\n",
    "\n",
    "for n in n_ests:\n",
    "    for dp in depths:\n",
    "        mod = ensemble.RandomForestClassifier(n_estimators = n, max_depth = dp)\n",
    "        mod.fit(x_train, y_train)\n",
    "        y_hat = mod.predict(x_test)\n",
    "        if accuracy_score(y_test, y_hat) > 0.83:\n",
    "            good_forest.append((n, dp))\n",
    "            print('------ Evaluating model: n_estimators =' + str(n) + ', max_depth = ' + str(dp),'------')\n",
    "            print_multiclass_classif_error_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 estimators and a max depth of 5\n",
      "Accuracy: 0.8461538461538461\n",
      "Avg. F1 (Micro): 0.8461538461538461\n",
      "Avg. F1 (Macro): 0.8460526315789474\n",
      "Avg. F1 (Weighted): 0.8457489878542509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85        22\n",
      "           1       0.76      0.94      0.84        17\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.85      0.86      0.85        39\n",
      "weighted avg       0.86      0.85      0.85        39\n",
      "\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 5 16]]\n"
     ]
    }
   ],
   "source": [
    "#Testing individual forest combinations.\n",
    "print('Using 50 estimators and a max depth of 5')\n",
    "rf_mod = ensemble.RandomForestClassifier(n_estimators = 50, max_depth = 5)\n",
    "rf_mod.fit(x_train, y_train)\n",
    "y_hat = rf_mod.predict(x_test)\n",
    "print_multiclass_classif_error_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Random Forest Testing\n",
    "The biggest issue with the random forest is that there is no obviously bester model. Especially since the accuracy of each estimator and max depth combination can change between tests. However, after running several tests the random forest utalizing 50 estimators and a max depth of 5 consistantly performed well. The random forest utalizing 80 estimators and a max depth of 6 also performed well, however, since it has a larger amount of estimators and the max depth is equal to the number of variables the model os more suseptable to overfitting so I believe that the model utalizing 50 estimators and a max depth of 5 is the best random forest model for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When n_estimators= 5 and max_depth= 5 the CV Score (Leave-One-Out)= 0.7109375\n",
      "When n_estimators= 10 and max_depth= 4 the CV Score (Leave-One-Out)= 0.7421875\n",
      "When n_estimators= 80 and max_depth= 2 the CV Score (Leave-One-Out)= 0.7578125\n",
      "When n_estimators= 80 and max_depth= 3 the CV Score (Leave-One-Out)= 0.765625\n",
      "When n_estimators= 80 and max_depth= 4 the CV Score (Leave-One-Out)= 0.7734375\n",
      "When n_estimators= 80 and max_depth= 5 the CV Score (Leave-One-Out)= 0.78125\n",
      "When n_estimators= 80 and max_depth= 6 the CV Score (Leave-One-Out)= 0.7578125\n"
     ]
    }
   ],
   "source": [
    "#Using leave-one-out cross validation to test the better performing random forests\n",
    "for i in range(len(good_forest)):\n",
    "    rf_mod = ensemble.RandomForestClassifier(n_estimators = good_forest[i][0], max_depth = good_forest[i][1])\n",
    "    loo = LeaveOneOut()\n",
    "    loo_scores = cross_val_score(rf_mod, data_x, data_y, cv=loo)\n",
    "    print('When n_estimators=',good_forest[i][0],'and max_depth=',good_forest[i][1],'the CV Score (Leave-One-Out)= ' + str(loo_scores.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When n_estimators= 5 and max_depth= 5 \n",
      " CV Scores (Shuffle Split)= [0.80769231 0.69230769 0.76923077 0.65384615 0.80769231 0.61538462\n",
      " 0.76923077 0.69230769 0.76923077 0.69230769]\n",
      "When n_estimators= 10 and max_depth= 4 \n",
      " CV Scores (Shuffle Split)= [0.84615385 0.73076923 0.65384615 0.61538462 0.76923077 0.73076923\n",
      " 0.84615385 0.76923077 0.80769231 0.61538462]\n",
      "When n_estimators= 80 and max_depth= 2 \n",
      " CV Scores (Shuffle Split)= [0.73076923 0.69230769 0.80769231 0.84615385 0.69230769 0.76923077\n",
      " 0.5        0.76923077 0.69230769 0.84615385]\n",
      "When n_estimators= 80 and max_depth= 3 \n",
      " CV Scores (Shuffle Split)= [0.61538462 0.80769231 0.88461538 0.73076923 0.80769231 0.80769231\n",
      " 0.73076923 0.65384615 0.80769231 0.92307692]\n",
      "When n_estimators= 80 and max_depth= 4 \n",
      " CV Scores (Shuffle Split)= [0.80769231 0.61538462 0.80769231 0.84615385 0.80769231 0.80769231\n",
      " 0.96153846 0.73076923 0.76923077 0.73076923]\n",
      "When n_estimators= 80 and max_depth= 5 \n",
      " CV Scores (Shuffle Split)= [0.88461538 0.76923077 0.76923077 0.80769231 0.92307692 0.73076923\n",
      " 0.80769231 0.76923077 0.73076923 0.76923077]\n",
      "When n_estimators= 80 and max_depth= 6 \n",
      " CV Scores (Shuffle Split)= [0.69230769 0.92307692 0.84615385 0.84615385 0.69230769 0.84615385\n",
      " 0.69230769 0.80769231 0.73076923 0.76923077]\n"
     ]
    }
   ],
   "source": [
    "# Using Shuffle Split cross validation to test the better performing random forests\n",
    "for i in range(len(good_forest)):\n",
    "    rf_mod = ensemble.RandomForestClassifier(n_estimators = good_forest[i][0], max_depth = good_forest[i][1])\n",
    "    shuffle_split = ShuffleSplit(test_size = 0.2, train_size = 0.8, n_splits = 10)\n",
    "    ss_scores = cross_val_score(rf_mod, data_x, data_y, scoring = 'accuracy', cv=shuffle_split)\n",
    "    print('When n_estimators=',good_forest[i][0],'and max_depth=',good_forest[i][1],'\\n CV Scores (Shuffle Split)= ' + str(ss_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: KNN\n",
    "K nearest neighbors performed better than the Naive Bayse model and about on par with the random forest. The model performed the best when k=5 with an accuracy of 0.846. At first glance the accuracy is lower than some of the random forest models however the accuracy of those models went down "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- EVALUATING MODEL: k = 1----------\n",
      "Accuracy: 0.7435897435897436\n",
      "Precision: 0.8235294117647058\n",
      "Recall: 0.6666666666666666\n",
      "F1: 0.7368421052631577\n",
      "ROC AUC: 0.75\n",
      "Confusion Matric: \n",
      "[[15  3]\n",
      " [ 7 14]]\n",
      "---------- EVALUATING MODEL: k = 3----------\n",
      "Accuracy: 0.7435897435897436\n",
      "Precision: 0.7894736842105263\n",
      "Recall: 0.7142857142857143\n",
      "F1: 0.7500000000000001\n",
      "ROC AUC: 0.746031746031746\n",
      "Confusion Matric: \n",
      "[[14  4]\n",
      " [ 6 15]]\n",
      "---------- EVALUATING MODEL: k = 5----------\n",
      "Accuracy: 0.8461538461538461\n",
      "Precision: 0.8947368421052632\n",
      "Recall: 0.8095238095238095\n",
      "F1: 0.8500000000000001\n",
      "ROC AUC: 0.8492063492063492\n",
      "Confusion Matric: \n",
      "[[16  2]\n",
      " [ 4 17]]\n",
      "---------- EVALUATING MODEL: k = 7----------\n",
      "Accuracy: 0.7692307692307693\n",
      "Precision: 0.9285714285714286\n",
      "Recall: 0.6190476190476191\n",
      "F1: 0.742857142857143\n",
      "ROC AUC: 0.7817460317460317\n",
      "Confusion Matric: \n",
      "[[17  1]\n",
      " [ 8 13]]\n",
      "---------- EVALUATING MODEL: k = 15----------\n",
      "Accuracy: 0.717948717948718\n",
      "Precision: 0.9166666666666666\n",
      "Recall: 0.5238095238095238\n",
      "F1: 0.6666666666666667\n",
      "ROC AUC: 0.7341269841269841\n",
      "Confusion Matric: \n",
      "[[17  1]\n",
      " [10 11]]\n"
     ]
    }
   ],
   "source": [
    "#Testing the KNN method with different values of k\n",
    "for k in range(1,20,2):\n",
    "    mod = knn.KNN(k, 'euclidean')\n",
    "    mod.fit(x_train, y_train)\n",
    "    y_hat = mod.predict(x_test)\n",
    "    if accuracy_score(y_test, y_hat) > .7:\n",
    "        print('---------- EVALUATING MODEL: k = ' + str(k) + '----------')\n",
    "        print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "        print('Precision: ' + str(precision_score(y_test, y_hat)))\n",
    "        print('Recall: ' + str(recall_score(y_test, y_hat)))\n",
    "        print('F1: ' + str(f1_score(y_test, y_hat)))\n",
    "        print('ROC AUC: ' + str(roc_auc_score(y_test, y_hat)))\n",
    "        print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Testing\n",
    "Since it is not very clear which is the best model I will test the best knn and the best random forest using the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- EVALUATING KNN MODEL: k = 5----------\n",
      "Accuracy: 0.71875\n",
      "Precision: 0.6428571428571429\n",
      "Recall: 0.6923076923076923\n",
      "F1: 0.6666666666666666\n",
      "ROC AUC: 0.7145748987854251\n",
      "Confusion Matric: \n",
      "[[14  5]\n",
      " [ 4  9]]\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "#Testing on the testing dataset\n",
    "knn_mod = knn.KNN(5, 'euclidean')\n",
    "mod = knn.KNN(k, 'euclidean')\n",
    "mod.fit(x_train, y_train)\n",
    "y_hat = mod.predict(data_x_testing)\n",
    "\n",
    "print('---------- EVALUATING KNN MODEL: k = ' + str(5) + '----------')\n",
    "print('Accuracy: ' + str(accuracy_score(data_test['Churn'], y_hat)))\n",
    "print('Precision: ' + str(precision_score(data_test['Churn'], y_hat)))\n",
    "print('Recall: ' + str(recall_score(data_test['Churn'], y_hat)))\n",
    "print('F1: ' + str(f1_score(data_test['Churn'], y_hat)))\n",
    "print('ROC AUC: ' + str(roc_auc_score(data_test['Churn'], y_hat)))\n",
    "print('Confusion Matric: \\n' + str(confusion_matrix(data_test['Churn'], y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- EVALUATING KNN MODEL: k = 5----------\n",
      "Accuracy: 0.71875\n",
      "Precision: 0.6428571428571429\n",
      "Recall: 0.6923076923076923\n",
      "F1: 0.6666666666666666\n",
      "ROC AUC: 0.7145748987854251\n",
      "Confusion Matric: \n",
      "[[14  5]\n",
      " [ 4  9]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "#Using \n",
    "rf_mod = ensemble.RandomForestClassifier(n_estimators = 50, max_depth = 5)\n",
    "rf_mod.fit(x_train, y_train)\n",
    "y_hat = mod.predict(data_x_testing)\n",
    "\n",
    "print('---------- EVALUATING KNN MODEL: k = ' + str(5) + '----------')\n",
    "print('Accuracy: ' + str(accuracy_score(data_test['Churn'], y_hat)))\n",
    "print('Precision: ' + str(precision_score(data_test['Churn'], y_hat)))\n",
    "print('Recall: ' + str(recall_score(data_test['Churn'], y_hat)))\n",
    "print('F1: ' + str(f1_score(data_test['Churn'], y_hat)))\n",
    "print('ROC AUC: ' + str(roc_auc_score(data_test['Churn'], y_hat)))\n",
    "print('Confusion Matric: \\n' + str(confusion_matrix(data_test['Churn'], y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "My best model was between the random forest and the knn however when I tested both on the churn_validation.csv dataset they gave the exact same results. They both had an accuracy of about 71% which is a decent model and aligns with some of the results that I was getting using the testing data on these models. As for how reliable it is, it isn't the most reliable model. I think that it is accurate enough that they can be beneficial however, I would only qualify it as a good reliable model if it were above 80% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
