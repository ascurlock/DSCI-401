{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine: How Does Characteristics Compare to Chemical Breakdown When Predicting The Rating Of a Wine?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Wine Reviews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4           4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN       Kerin O’Keefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('winemag-data-130k-v2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "In order to maximize the data first I dropped the taster_twitter_handle since it is repeated data. Then since I couldn't work with the title and discription columns of the wine but I thought that it would be interesting to see if the number of words in the wine's name or description was influencial.\n",
    "    \n",
    " One issue I found was that many of the designation lables weren't the same. For example some would have extra dashes or words would be plural while some would be singular, there would be an extra connecting word, or it would be the same name but in another language. So to help fix his problem I made the column lowercase and removing any rows where the designation lable didn't appear more than 10 times. This went for several other columns.\n",
    "\n",
    "As for any missing data if the data was numeric I dropped the row and if it was catagorical I replaces it with a 'None\" string. Though I could have done more to help preserve the size of the dataframe I think that redicing it is the better choice since the Wine Quality dataframe only has about 6500 rows. If the wine reviews dataframe is significantly bigger then the model could perform better just on the principle that it has more data to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "data = data.drop(labels=['taster_twitter_handle'], axis = 1)\n",
    "\n",
    "# Delete rows where columns have a small number of nans\n",
    "data = data.drop([86909], axis = 0)\n",
    "data = data[pd.notnull(data['country'])]\n",
    "# replace nan values with none\n",
    "data = data.dropna(subset = ['price']) #dropped all rows that didn't include price \n",
    "    # MAYBE GO BACK CAND CHANGE THIS\n",
    "data = data.fillna(value = 'None')\n",
    "# This reduces the data frok 130,000 to 120,915\n",
    "\n",
    "# Get the length of each wine name\n",
    "title_length = [len(x.split()) for x in list(data['title'])]\n",
    "data['title_length'] = title_length\n",
    "data = data.drop(labels=['title'], axis = 1)\n",
    "\n",
    "# Get the length of each wine description\n",
    "description_length = [len(x.split()) for x in list(data['description'])]\n",
    "data['description_length'] = description_length\n",
    "data = data.drop(labels=['description'], axis = 1)\n",
    "\n",
    "# adjust points so that they are on the same scale as the other dataset\n",
    "data.points.div(10)\n",
    "\n",
    "data['designation'] = data['designation'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>title_length</th>\n",
       "      <th>description_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>none</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>France</td>\n",
       "      <td>none</td>\n",
       "      <td>87</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>None</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>Gewürztraminer</td>\n",
       "      <td>Trimbach</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>France</td>\n",
       "      <td>les natures</td>\n",
       "      <td>87</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>None</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Jean-Baptiste Adam</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>US</td>\n",
       "      <td>mountain cuvée</td>\n",
       "      <td>87</td>\n",
       "      <td>19.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Virginie Boone</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Kirkland Signature</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>France</td>\n",
       "      <td>none</td>\n",
       "      <td>87</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>None</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>Gewürztraminer</td>\n",
       "      <td>Leon Beyer</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 country     designation  points  price    province  \\\n",
       "2            2      US            none      87   14.0      Oregon   \n",
       "7            7  France            none      87   24.0      Alsace   \n",
       "9            9  France     les natures      87   27.0      Alsace   \n",
       "10          10      US  mountain cuvée      87   19.0  California   \n",
       "11          11  France            none      87   30.0      Alsace   \n",
       "\n",
       "             region_1           region_2     taster_name             variety  \\\n",
       "2   Willamette Valley  Willamette Valley    Paul Gregutt          Pinot Gris   \n",
       "7              Alsace               None      Roger Voss      Gewürztraminer   \n",
       "9              Alsace               None      Roger Voss          Pinot Gris   \n",
       "10        Napa Valley               Napa  Virginie Boone  Cabernet Sauvignon   \n",
       "11             Alsace               None      Roger Voss      Gewürztraminer   \n",
       "\n",
       "                winery  title_length  description_length  \n",
       "2            Rainstorm             6                  28  \n",
       "7             Trimbach             4                  21  \n",
       "9   Jean-Baptiste Adam             8                  30  \n",
       "10  Kirkland Signature             9                  36  \n",
       "11          Leon Beyer             5                  32  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Many of the wines are very unique so I removed the wines that only appeared a handfull of times\n",
    "data = data[data['designation'].isin([k for k, v in Counter(list(data['designation'])).items() if v > 10])]\n",
    "data = data[data['country'].isin([k for k, v in Counter(list(data['country'])).items() if v > 89])]\n",
    "data = data[data['variety'].isin([k for k, v in Counter(list(data['variety'])).items() if v > 10])]\n",
    "data = data[data['winery'].isin([k for k, v in Counter(list(data['winery'])).items() if v > 10])]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another variable if the wine is from the top 10 countries known for wine\n",
    "top10 = []\n",
    "notTop10 = []\n",
    "for i in list(data['country'].isin(['France', 'Italy','Spain','US','Argentina','Australia','Germany','South Afrca','Chile','Portugal'])):\n",
    "    if i:\n",
    "        top10.append(1)\n",
    "        notTop10.append(0)\n",
    "    else:\n",
    "        top10.append(0)\n",
    "        notTop10.append(1)\n",
    "top10        \n",
    "data['top10_Country'] = top10\n",
    "data['notTop10_Country'] = notTop10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test sets\n",
    "features = list(data)\n",
    "features.remove('Unnamed: 0')\n",
    "features.remove('points')\n",
    "\n",
    "\n",
    "# Create training and test splits\n",
    "data_x = data[features]\n",
    "data_y = data['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>title_length</th>\n",
       "      <th>description_length</th>\n",
       "      <th>top10_Country</th>\n",
       "      <th>notTop10_Country</th>\n",
       "      <th>country_Argentina</th>\n",
       "      <th>country_Australia</th>\n",
       "      <th>country_Austria</th>\n",
       "      <th>country_Canada</th>\n",
       "      <th>country_Chile</th>\n",
       "      <th>...</th>\n",
       "      <th>winery_Zaca Mesa</th>\n",
       "      <th>winery_Zantho</th>\n",
       "      <th>winery_Zenato</th>\n",
       "      <th>winery_Zina Hyde Cunningham</th>\n",
       "      <th>winery_Zolo</th>\n",
       "      <th>winery_Zorzal</th>\n",
       "      <th>winery_Zotovich Cellars</th>\n",
       "      <th>winery_Zuccardi</th>\n",
       "      <th>winery_oops</th>\n",
       "      <th>winery_àMaurice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.0</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2655 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  title_length  description_length  top10_Country  notTop10_Country  \\\n",
       "2    14.0             6                  28              1                 0   \n",
       "7    24.0             4                  21              1                 0   \n",
       "9    27.0             8                  30              1                 0   \n",
       "10   19.0             9                  36              1                 0   \n",
       "11   30.0             5                  32              1                 0   \n",
       "\n",
       "    country_Argentina  country_Australia  country_Austria  country_Canada  \\\n",
       "2                   0                  0                0               0   \n",
       "7                   0                  0                0               0   \n",
       "9                   0                  0                0               0   \n",
       "10                  0                  0                0               0   \n",
       "11                  0                  0                0               0   \n",
       "\n",
       "    country_Chile       ...         winery_Zaca Mesa  winery_Zantho  \\\n",
       "2               0       ...                        0              0   \n",
       "7               0       ...                        0              0   \n",
       "9               0       ...                        0              0   \n",
       "10              0       ...                        0              0   \n",
       "11              0       ...                        0              0   \n",
       "\n",
       "    winery_Zenato  winery_Zina Hyde Cunningham  winery_Zolo  winery_Zorzal  \\\n",
       "2               0                            0            0              0   \n",
       "7               0                            0            0              0   \n",
       "9               0                            0            0              0   \n",
       "10              0                            0            0              0   \n",
       "11              0                            0            0              0   \n",
       "\n",
       "    winery_Zotovich Cellars  winery_Zuccardi  winery_oops  winery_àMaurice  \n",
       "2                         0                0            0                0  \n",
       "7                         0                0            0                0  \n",
       "9                         0                0            0                0  \n",
       "10                        0                0            0                0  \n",
       "11                        0                0            0                0  \n",
       "\n",
       "[5 rows x 2655 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-Hot Encode Variables\n",
    "data_x = pd.get_dummies(data_x, columns=['country','designation', 'province', 'region_1','region_2','taster_name','variety','winery'])\n",
    "data_x.head() #(26614 rows, 2655 columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price and points have a correlation of 0.45111736218256504\n",
      "title_length and points have a correlation of 0.16559143968374196\n",
      "description_length and points have a correlation of 0.5282095837360421\n",
      "country_Argentina and points have a correlation of -0.13629617149124115\n",
      "country_Chile and points have a correlation of -0.2018660991979389\n",
      "designation_none and points have a correlation of -0.13639135297731977\n",
      "province_Mendoza Province and points have a correlation of -0.13026934455593983\n",
      "region_1_California and points have a correlation of -0.1616470226311091\n",
      "region_1_Mendoza and points have a correlation of -0.11652650519756004\n",
      "region_1_None and points have a correlation of -0.10989429989644192\n",
      "region_2_California Other and points have a correlation of -0.1629026828667652\n",
      "taster_name_Anne Krebiehl MW and points have a correlation of 0.11680126614511858\n",
      "taster_name_Matt Kettmann and points have a correlation of 0.1416627517673968\n",
      "taster_name_Michael Schachner and points have a correlation of -0.24683378570475292\n",
      "variety_Pinot Noir and points have a correlation of 0.11660349978665253\n",
      "variety_Sauvignon Blanc and points have a correlation of -0.10196484154605417\n"
     ]
    }
   ],
   "source": [
    "# To try to better understand the data I tested the correlation between the points and the other variables which \n",
    "#showed to have insignificant correlation\n",
    "correlated_values = []\n",
    "for i in list(data_x):\n",
    "    if data_x[i].corr(data_y) > .1 or data_x[i].corr(data_y) < -.1:\n",
    "        print(i,'and points have a correlation of', data_x[i].corr(data_y))\n",
    "        correlated_values.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and Final test sets\n",
    "x_train, x_test1, y_train, y_test1 = train_test_split(data_x, data_y, test_size = 0.2, random_state = 4)\n",
    "\n",
    "#Split the data again to help build the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling\n",
    "To model this data I tried SVM, Random Forest, Naieve Bayse, and liner regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "Since the data has so many columns I thought that trying a SVM would be a good start in trying to model the data. However, the model was terribly inaccurate. When using all of the vaiables no value of c could make the accuracy greater than 20%. This only improved slightly when variables that were less correlated were removed making the accuraccy slightly greater than 20% for all c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Evaluating model: C= =1.0---------\n",
      "Accuracy: 0.18614130434782608\n",
      "Avg. F1 (Micro): 0.18614130434782608\n",
      "Avg. F1 (Macro): 0.07771317737913737\n",
      "Avg. F1 (Weighted): 0.2551045466642685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          80       0.00      0.00      0.00        13\n",
      "          81       0.00      0.00      0.00        25\n",
      "          82       0.00      0.00      0.00        76\n",
      "          83       0.00      0.00      0.00        88\n",
      "          84       0.00      0.00      0.00       267\n",
      "          85       0.00      0.00      0.00       368\n",
      "          86       0.00      0.00      0.00       474\n",
      "          87       0.19      0.65      0.30       651\n",
      "          88       0.19      0.27      0.22       631\n",
      "          89       0.00      0.00      0.00       402\n",
      "          90       0.16      0.30      0.21       539\n",
      "          91       0.00      0.00      0.00       367\n",
      "          92       0.19      0.22      0.20       238\n",
      "          93       0.33      0.01      0.03       149\n",
      "          94       0.29      0.07      0.11        85\n",
      "          95       0.31      0.17      0.22        29\n",
      "          96       1.00      0.10      0.18        10\n",
      "          97       0.00      0.00      0.00         3\n",
      "          98       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.19      0.19      0.19      4416\n",
      "   macro avg       0.14      0.09      0.08      4416\n",
      "weighted avg       0.11      0.19      0.12      4416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create model and fit using all variables\n",
    "mod = svm.SVC(C=1.0)\n",
    "mod.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_hat = mod.predict(x_test)\n",
    "print('--------- Evaluating model: C= =' + str(1.0) + '---------')\n",
    "print('Accuracy: ' + str(accuracy_score(y_hat, y_test)))\n",
    "print('Avg. F1 (Micro): ' + str(f1_score(y_hat, y_test, average='micro')))\n",
    "print('Avg. F1 (Macro): ' + str(f1_score(y_hat, y_test, average='macro')))\n",
    "print('Avg. F1 (Weighted): ' + str(f1_score(y_hat, y_test, average='weighted')))\n",
    "print(classification_report(y_test, y_hat))\n",
    "#print('Confusion Matrix: \\n' + str(confusion_matrix(y_hat, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Evaluating model: C= =0.2---------\n",
      "Accuracy: 0.20497769429443533\n",
      "Avg. F1 (Micro): 0.20497769429443533\n",
      "Avg. F1 (Macro): 0.08615748649808726\n",
      "Avg. F1 (Weighted): 0.2455218400117748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          80       0.00      0.00      0.00         8\n",
      "          81       0.00      0.00      0.00        30\n",
      "          82       0.50      0.11      0.18        75\n",
      "          83       0.00      0.00      0.00       125\n",
      "          84       0.23      0.12      0.15       224\n",
      "          85       0.23      0.09      0.13       330\n",
      "          86       0.28      0.10      0.15       463\n",
      "          87       0.21      0.54      0.30       596\n",
      "          88       0.20      0.26      0.23       605\n",
      "          89       0.00      0.00      0.00       371\n",
      "          90       0.17      0.39      0.24       505\n",
      "          91       0.33      0.09      0.14       342\n",
      "          92       0.20      0.22      0.21       268\n",
      "          93       0.00      0.00      0.00       150\n",
      "          94       0.00      0.00      0.00       108\n",
      "          95       0.00      0.00      0.00        47\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         3\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.20      0.20      0.20      4259\n",
      "   macro avg       0.12      0.10      0.09      4259\n",
      "weighted avg       0.19      0.20      0.16      4259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Evaluating model: C= =0.5---------\n",
      "Accuracy: 0.2089692416060108\n",
      "Avg. F1 (Micro): 0.2089692416060108\n",
      "Avg. F1 (Macro): 0.10023020313968649\n",
      "Avg. F1 (Weighted): 0.2403170527993255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          80       0.00      0.00      0.00         8\n",
      "          81       0.00      0.00      0.00        30\n",
      "          82       0.46      0.16      0.24        75\n",
      "          83       0.00      0.00      0.00       125\n",
      "          84       0.19      0.13      0.15       224\n",
      "          85       0.20      0.12      0.15       330\n",
      "          86       0.23      0.12      0.16       463\n",
      "          87       0.22      0.50      0.30       596\n",
      "          88       0.20      0.25      0.23       605\n",
      "          89       0.00      0.00      0.00       371\n",
      "          90       0.19      0.34      0.24       505\n",
      "          91       0.24      0.14      0.18       342\n",
      "          92       0.20      0.27      0.23       268\n",
      "          93       0.20      0.05      0.08       150\n",
      "          94       0.20      0.02      0.03       108\n",
      "          95       0.00      0.00      0.00        47\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         3\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.21      0.21      0.21      4259\n",
      "   macro avg       0.13      0.11      0.10      4259\n",
      "weighted avg       0.18      0.21      0.18      4259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Evaluating model: C= =1.0---------\n",
      "Accuracy: 0.21037802301009625\n",
      "Avg. F1 (Micro): 0.21037802301009625\n",
      "Avg. F1 (Macro): 0.11723941633127358\n",
      "Avg. F1 (Weighted): 0.23308994839915895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          80       0.00      0.00      0.00         8\n",
      "          81       0.00      0.00      0.00        30\n",
      "          82       0.45      0.20      0.28        75\n",
      "          83       0.50      0.02      0.05       125\n",
      "          84       0.20      0.17      0.18       224\n",
      "          85       0.21      0.15      0.17       330\n",
      "          86       0.19      0.11      0.14       463\n",
      "          87       0.21      0.44      0.29       596\n",
      "          88       0.21      0.27      0.24       605\n",
      "          89       0.06      0.01      0.01       371\n",
      "          90       0.20      0.31      0.24       505\n",
      "          91       0.24      0.18      0.21       342\n",
      "          92       0.21      0.23      0.22       268\n",
      "          93       0.20      0.11      0.14       150\n",
      "          94       0.28      0.14      0.19       108\n",
      "          95       0.00      0.00      0.00        47\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         3\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.21      0.21      0.21      4259\n",
      "   macro avg       0.16      0.12      0.12      4259\n",
      "weighted avg       0.20      0.21      0.19      4259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Evaluating model: C= =2.0---------\n",
      "Accuracy: 0.2129607889175863\n",
      "Avg. F1 (Micro): 0.21296078891758632\n",
      "Avg. F1 (Macro): 0.12430714112241996\n",
      "Avg. F1 (Weighted): 0.23031877124204272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          80       0.00      0.00      0.00         8\n",
      "          81       0.00      0.00      0.00        30\n",
      "          82       0.40      0.19      0.25        75\n",
      "          83       0.35      0.05      0.08       125\n",
      "          84       0.21      0.18      0.19       224\n",
      "          85       0.23      0.17      0.19       330\n",
      "          86       0.20      0.12      0.15       463\n",
      "          87       0.21      0.42      0.28       596\n",
      "          88       0.22      0.29      0.25       605\n",
      "          89       0.17      0.04      0.06       371\n",
      "          90       0.22      0.30      0.25       505\n",
      "          91       0.20      0.16      0.18       342\n",
      "          92       0.20      0.21      0.21       268\n",
      "          93       0.20      0.14      0.17       150\n",
      "          94       0.21      0.12      0.15       108\n",
      "          95       0.18      0.04      0.07        47\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         3\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.21      0.21      0.21      4259\n",
      "   macro avg       0.16      0.12      0.12      4259\n",
      "weighted avg       0.21      0.21      0.20      4259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Evaluating model: C= =5.0---------\n",
      "Accuracy: 0.21366517961962903\n",
      "Avg. F1 (Micro): 0.21366517961962903\n",
      "Avg. F1 (Macro): 0.12818245475578516\n",
      "Avg. F1 (Weighted): 0.22509907114571928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          80       0.00      0.00      0.00         8\n",
      "          81       0.08      0.03      0.05        30\n",
      "          82       0.23      0.09      0.13        75\n",
      "          83       0.30      0.09      0.14       125\n",
      "          84       0.25      0.22      0.23       224\n",
      "          85       0.22      0.18      0.20       330\n",
      "          86       0.17      0.12      0.14       463\n",
      "          87       0.22      0.38      0.28       596\n",
      "          88       0.22      0.28      0.24       605\n",
      "          89       0.18      0.08      0.11       371\n",
      "          90       0.22      0.29      0.25       505\n",
      "          91       0.20      0.16      0.18       342\n",
      "          92       0.23      0.23      0.23       268\n",
      "          93       0.20      0.15      0.17       150\n",
      "          94       0.18      0.13      0.15       108\n",
      "          95       0.11      0.04      0.06        47\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         3\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.21      0.21      0.21      4259\n",
      "   macro avg       0.15      0.12      0.13      4259\n",
      "weighted avg       0.21      0.21      0.20      4259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Evaluating model: C= =6.0---------\n",
      "Accuracy: 0.21460436722235265\n",
      "Avg. F1 (Micro): 0.21460436722235265\n",
      "Avg. F1 (Macro): 0.12962588206615633\n",
      "Avg. F1 (Weighted): 0.22544413943357228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          80       0.00      0.00      0.00         8\n",
      "          81       0.07      0.03      0.05        30\n",
      "          82       0.23      0.09      0.13        75\n",
      "          83       0.28      0.08      0.12       125\n",
      "          84       0.26      0.22      0.24       224\n",
      "          85       0.22      0.18      0.20       330\n",
      "          86       0.17      0.13      0.15       463\n",
      "          87       0.22      0.38      0.28       596\n",
      "          88       0.22      0.28      0.25       605\n",
      "          89       0.19      0.09      0.12       371\n",
      "          90       0.22      0.28      0.25       505\n",
      "          91       0.19      0.16      0.17       342\n",
      "          92       0.22      0.22      0.22       268\n",
      "          93       0.21      0.14      0.17       150\n",
      "          94       0.21      0.17      0.19       108\n",
      "          95       0.10      0.04      0.06        47\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         3\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.21      0.21      0.21      4259\n",
      "   macro avg       0.15      0.13      0.13      4259\n",
      "weighted avg       0.21      0.21      0.20      4259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Evaluating model: C= =10---------\n",
      "Accuracy: 0.21460436722235265\n",
      "Avg. F1 (Micro): 0.21460436722235265\n",
      "Avg. F1 (Macro): 0.13304997634056923\n",
      "Avg. F1 (Weighted): 0.2225615066070718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          80       0.00      0.00      0.00         8\n",
      "          81       0.07      0.03      0.04        30\n",
      "          82       0.19      0.09      0.12        75\n",
      "          83       0.21      0.07      0.11       125\n",
      "          84       0.26      0.22      0.24       224\n",
      "          85       0.19      0.18      0.18       330\n",
      "          86       0.18      0.14      0.16       463\n",
      "          87       0.22      0.36      0.27       596\n",
      "          88       0.22      0.26      0.24       605\n",
      "          89       0.20      0.12      0.15       371\n",
      "          90       0.23      0.28      0.25       505\n",
      "          91       0.19      0.16      0.17       342\n",
      "          92       0.26      0.24      0.25       268\n",
      "          93       0.21      0.15      0.18       150\n",
      "          94       0.25      0.18      0.21       108\n",
      "          95       0.12      0.06      0.08        47\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         3\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.21      0.21      0.21      4259\n",
      "   macro avg       0.15      0.13      0.13      4259\n",
      "weighted avg       0.21      0.21      0.21      4259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "C <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-eb155e57fd04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create model and fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorrelated_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: C <= 0"
     ]
    }
   ],
   "source": [
    "# Create model and fit for different values of c using only correlated vairables.\n",
    "\n",
    "cs = [0.2, 0.5 ,1.0 ,2.0 ,5.0, 6.0, 10,0]\n",
    "for c in cs:\n",
    "# Create model and fit\n",
    "    mod = svm.SVC(C=c)\n",
    "    mod.fit(x_train[correlated_values], y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_hat = mod.predict(x_test[correlated_values])\n",
    "    print('--------- Evaluating model: C= =' + str(c) + '---------')\n",
    "    print('Accuracy: ' + str(accuracy_score(y_hat, y_test)))\n",
    "    print('Avg. F1 (Micro): ' + str(f1_score(y_hat, y_test, average='micro')))\n",
    "    print('Avg. F1 (Macro): ' + str(f1_score(y_hat, y_test, average='macro')))\n",
    "    print('Avg. F1 (Weighted): ' + str(f1_score(y_hat, y_test, average='weighted')))\n",
    "    print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and fit for different values of c using all variables.\n",
    "\n",
    "cs = [0.2, 0.5 ,1.0 ,2.0 ,5.0, 6.0, 10,0]\n",
    "for c in cs:\n",
    "# Create model and fit\n",
    "    mod = svm.SVC(C=c)\n",
    "    mod.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_hat = mod.predict(x_test)\n",
    "    print('--------- Evaluating model: C= =' + str(c) + '---------')\n",
    "    print('Accuracy: ' + str(accuracy_score(y_hat, y_test)))\n",
    "    print('Avg. F1 (Micro): ' + str(f1_score(y_hat, y_test, average='micro')))\n",
    "    print('Avg. F1 (Macro): ' + str(f1_score(y_hat, y_test, average='macro')))\n",
    "    print('Avg. F1 (Weighted): ' + str(f1_score(y_hat, y_test, average='weighted')))\n",
    "    print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayse\n",
    "This model performed about the same as the SVM. However in this instance the accuacy decreased from 0.186 to 0.137 when the less correlated variables were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.18666353604132427\n",
      "Confusion Matric: \n",
      "[[  0   0   0   0   1   1   2   2   0   0   1   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   7   6   4   8   1   0   1   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1  24  11   5  16   6   0  10   1   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0  20  27  19  29  11   4  13   1   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   4  38  42  37  40  20   4  33   5   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   2  34  60  44  67  47  18  42   8   8   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   3  38  63  67  84  82  27  63  16  19   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   6  32  68  72 132 107  42  88  20  25   4   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1  19  48  43  99 126  75  97  45  48   4   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0  12  20  25  58  62  65  58  37  27   7   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   8  19  15  53  71  73 160  48  49   9   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   2  10   7  28  41  36  94  71  43   9   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   5   5  15  23  29  63  46  63  19   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   2   1   3   7  11  38  26  49  13   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   1  11   5  22  11  38  19   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   1   0   0   7   5  11   4   7  11   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   4   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   2   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0\n",
      "    0   0]]\n"
     ]
    }
   ],
   "source": [
    "#Naieve Bayse Using All vairables\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "nb = naive_bayes.BernoulliNB()\n",
    "#nb = naive_bayes.GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_hat = nb.predict(x_test)\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.13759098379901386\n",
      "Confusion Matric: \n",
      "[[  0   0   0   0   0   1   1   1   1   0   4   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4   0   0   0   5   4   0   1   8   0   7   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3   0   0   0  18   7   1   4  26   0  14   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 12   0   0   3  12  14   7   8  41   0  26   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 13   0   0   2  22  27   8  13  97   0  40   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 10   0   0   3  21  35  12  22 141   0  76   0   9   1   0   0   0   0\n",
      "    0   0]\n",
      " [  9   0   0   4  26  48  11  30 200   2 115   0  17   1   0   0   0   0\n",
      "    0   0]\n",
      " [ 16   0   0  11  19  54  16  39 253   1 161   0  25   1   0   0   0   0\n",
      "    0   0]\n",
      " [ 13   0   0   6  11  31  11  44 249   5 183   0  45   7   0   0   0   0\n",
      "    0   0]\n",
      " [  6   0   0   3   6  12   6  29 136   6 141   0  24   2   0   0   0   0\n",
      "    0   0]\n",
      " [  3   0   0   1   3  11   3  33 227  11 166   0  37  10   0   0   0   0\n",
      "    0   0]\n",
      " [  2   0   0   1   1   3   0  19 130   5 143   0  29   9   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   1   0   8  81   9 110   0  44  14   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   8  35   2  62   0  32  11   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   0   0   2  25   3  43   0  21  13   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   2   6   3  24   0   7   4   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   1   2   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   2   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0\n",
      "    0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Using Naieve Bayse using correlated data\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "nb = naive_bayes.BernoulliNB()\n",
    "#nb = naive_bayes.GaussianNB()\n",
    "nb.fit(x_train[correlated_values], y_train)\n",
    "y_hat = nb.predict(x_test[correlated_values])\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Evaluating model: n_estimators =5, max_depth = 50 ------\n",
      "Accuracy: 0.25099788682789387\n",
      "------ Evaluating model: n_estimators =5, max_depth = 100 ------\n",
      "Accuracy: 0.2526414651326602\n",
      "------ Evaluating model: n_estimators =5, max_depth = 200 ------\n",
      "Accuracy: 0.25686780934491665\n",
      "------ Evaluating model: n_estimators =5, max_depth = 300 ------\n",
      "Accuracy: 0.2519370744306175\n",
      "------ Evaluating model: n_estimators =5, max_depth = 1000 ------\n",
      "Accuracy: 0.25146748062925567\n",
      "------ Evaluating model: n_estimators =10, max_depth = 40 ------\n",
      "Accuracy: 0.2601549659544494\n",
      "------ Evaluating model: n_estimators =10, max_depth = 50 ------\n",
      "Accuracy: 0.263911716365344\n",
      "------ Evaluating model: n_estimators =10, max_depth = 100 ------\n",
      "Accuracy: 0.27353838929326135\n",
      "------ Evaluating model: n_estimators =10, max_depth = 200 ------\n",
      "Accuracy: 0.27424277999530405\n",
      "------ Evaluating model: n_estimators =10, max_depth = 300 ------\n",
      "Accuracy: 0.27424277999530405\n",
      "------ Evaluating model: n_estimators =10, max_depth = 1000 ------\n",
      "Accuracy: 0.27142521718713314\n",
      "------ Evaluating model: n_estimators =50, max_depth = 30 ------\n",
      "Accuracy: 0.2693120450810049\n",
      "------ Evaluating model: n_estimators =50, max_depth = 40 ------\n",
      "Accuracy: 0.27706034280347497\n",
      "------ Evaluating model: n_estimators =50, max_depth = 50 ------\n",
      "Accuracy: 0.2833998591218596\n",
      "------ Evaluating model: n_estimators =50, max_depth = 100 ------\n",
      "Accuracy: 0.27659074900211317\n",
      "------ Evaluating model: n_estimators =50, max_depth = 200 ------\n",
      "Accuracy: 0.2789387180089223\n",
      "------ Evaluating model: n_estimators =50, max_depth = 300 ------\n",
      "Accuracy: 0.28058229631368864\n",
      "------ Evaluating model: n_estimators =50, max_depth = 1000 ------\n",
      "Accuracy: 0.2777647335055177\n",
      "------ Evaluating model: n_estimators =80, max_depth = 30 ------\n",
      "Accuracy: 0.27212960788917584\n",
      "------ Evaluating model: n_estimators =80, max_depth = 40 ------\n",
      "Accuracy: 0.2836346560225405\n",
      "------ Evaluating model: n_estimators =80, max_depth = 50 ------\n",
      "Accuracy: 0.28833059403615874\n",
      "------ Evaluating model: n_estimators =80, max_depth = 100 ------\n",
      "Accuracy: 0.2864522188307114\n",
      "------ Evaluating model: n_estimators =80, max_depth = 200 ------\n",
      "Accuracy: 0.2794083118102841\n",
      "------ Evaluating model: n_estimators =80, max_depth = 300 ------\n",
      "Accuracy: 0.2784691242075605\n",
      "------ Evaluating model: n_estimators =80, max_depth = 1000 ------\n",
      "Accuracy: 0.28199107771777415\n",
      "------ Evaluating model: n_estimators =100, max_depth = 30 ------\n",
      "Accuracy: 0.2794083118102841\n",
      "------ Evaluating model: n_estimators =100, max_depth = 40 ------\n",
      "Accuracy: 0.2836346560225405\n",
      "------ Evaluating model: n_estimators =100, max_depth = 50 ------\n",
      "Accuracy: 0.28222587461845505\n",
      "------ Evaluating model: n_estimators =100, max_depth = 100 ------\n",
      "Accuracy: 0.2841042498239023\n",
      "------ Evaluating model: n_estimators =100, max_depth = 200 ------\n",
      "Accuracy: 0.2791735149096032\n",
      "------ Evaluating model: n_estimators =100, max_depth = 300 ------\n",
      "Accuracy: 0.2812866870157314\n",
      "------ Evaluating model: n_estimators =100, max_depth = 1000 ------\n",
      "Accuracy: 0.2775299366048368\n",
      "------ Evaluating model: n_estimators =200, max_depth = 30 ------\n",
      "Accuracy: 0.2751819675980277\n",
      "------ Evaluating model: n_estimators =200, max_depth = 40 ------\n",
      "Accuracy: 0.2918525475463724\n",
      "------ Evaluating model: n_estimators =200, max_depth = 50 ------\n",
      "Accuracy: 0.2873914064334351\n",
      "------ Evaluating model: n_estimators =200, max_depth = 100 ------\n",
      "Accuracy: 0.2810518901150505\n",
      "------ Evaluating model: n_estimators =200, max_depth = 200 ------\n",
      "Accuracy: 0.28034749941300774\n"
     ]
    }
   ],
   "source": [
    "#Random Forest using all variables\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Builds a sequence of Random Forest models for different n_est and depth values\n",
    "n_ests = [5, 10, 50, 80, 100, 200, 1000]\n",
    "depths = [15, 16, 17, 18, 19, 20, 30, 40, 50, 100, 200, 300, 1000]\n",
    "\n",
    "# Creates a list of tuples containing the n-est and depth values that perform well (n-est, depth)\n",
    "good_forest = []\n",
    "\n",
    "for n in n_ests:\n",
    "    for dp in depths:\n",
    "        mod = ensemble.RandomForestClassifier(n_estimators = n, max_depth = dp)\n",
    "        mod.fit(x_train, y_train)\n",
    "        y_hat = mod.predict(x_test)\n",
    "        good_forest.append((n, dp))\n",
    "        if accuracy_score(y_test, y_hat) > .25:\n",
    "            print('------ Evaluating model: n_estimators =' + str(n) + ', max_depth = ' + str(dp),'------')\n",
    "            print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "            #print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try Random Forrest. Does not perform well. Accuracy < 25%\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Builds a sequence of Random Forest models for different n_est and depth values\n",
    "n_ests = [5, 10, 50, 80]\n",
    "depths = [30, 40, 50, 100, 200, 300, 1000]\n",
    "\n",
    "# Creates a list of tuples containing the n-est and depth values that perform well (n-est, depth)\n",
    "good_forest = []\n",
    "\n",
    "for n in n_ests:\n",
    "    for dp in depths:\n",
    "        mod = ensemble.RandomForestClassifier(n_estimators = n, max_depth = dp)\n",
    "        mod.fit(x_train[correlated_values], y_train)\n",
    "        y_hat = mod.predict(x_test[correlated_values])\n",
    "        good_forest.append((n, dp))\n",
    "        if accuracy_score(y_test, y_hat) > .2:\n",
    "            print('------ Evaluating model: n_estimators =' + str(n) + ', max_depth = ' + str(dp),'------')\n",
    "            print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "            #print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Knn using all variables\n",
    "from sklearn import neighbors\n",
    "\n",
    "#Trying KNN Algorithm\n",
    "ks = [3, 5, 7, 9, 11, 13, 15, 17, 19] #Using odd numbers to make sure it doesn't end in a tie\n",
    "for k in ks:\n",
    "    # Create model and fit.\n",
    "    mod = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
    "    mod.fit(x_train, y_train)\n",
    "    \n",
    "    #Made predictions and look at results.\n",
    "    y_hat = mod.predict(x_test)\n",
    "    if accuracy_score(y_test, y_hat) > .53:\n",
    "        print('---------- EVALUATING MODEL: k = ' + str(k) + '----------')\n",
    "        print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "        #print('Precision: ' + str(precision_score(y_test, y_hat)))\n",
    "        #print('Recall: ' + str(recall_score(y_test, y_hat)))\n",
    "        #print('F1: ' + str(f1_score(y_test, y_hat)))\n",
    "        #print('ROC AUC: ' + str(roc_auc_score(y_test, y_hat)))\n",
    "        print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Knn on correlated variables\n",
    "from sklearn import neighbors\n",
    "\n",
    "#Trying KNN Algorithm\n",
    "ks = [3, 5, 7, 9, 11, 13, 15, 17, 19] #Using odd numbers to make sure it doesn't end in a tie\n",
    "for k in ks:\n",
    "    # Create model and fit.\n",
    "    mod = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
    "    mod.fit(x_train[correlated_values], y_train)\n",
    "    \n",
    "    #Made predictions and look at results.\n",
    "    y_hat = mod.predict(x_test[correlated_values])\n",
    "    if accuracy_score(y_test, y_hat) > .53:\n",
    "        print('---------- EVALUATING MODEL: k = ' + str(k) + '----------')\n",
    "        print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "        #print('Precision: ' + str(precision_score(y_test, y_hat)))\n",
    "        #print('Recall: ' + str(recall_score(y_test, y_hat)))\n",
    "        #print('F1: ' + str(f1_score(y_test, y_hat)))\n",
    "        #print('ROC AUC: ' + str(roc_auc_score(y_test, y_hat)))\n",
    "        print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "The next attempt is to create a linear regression which worked significantly better than the SVM. With a degree of 2 the model has an accuracy of 0.516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Actual  Predicted\n",
      "107813      88  87.253087\n",
      "2172        90  89.661229\n",
      "65831       86  86.883429\n",
      "115828      87  85.238751\n",
      "102028      86  85.642993\n",
      "With Degree= 1\n",
      "Mean Squared Error, \n",
      "7.320432856753048e+16\n",
      "R^2 \n",
      "-8166956925598678.0\n",
      "Median Absolute Error \n",
      "1.2900972366333008\n",
      "Expected Variance Explained: \n",
      "-8162873120550754.0\n"
     ]
    }
   ],
   "source": [
    "# Check if Quadradic models work any better. Comparing how using the entire dataset compares to using\n",
    "#only the variables with higher correlation. The Model with degree 2 performed better.\n",
    "degree = [1,2,3]\n",
    "for i in degree:\n",
    "    # Create a quadratic variable preprocessor\n",
    "    quad = PolynomialFeatures(degree = i)\n",
    "    # Fit and transform the data\n",
    "    data_x_2 = quad.fit_transform(x_train)\n",
    "\n",
    "    x_train2,x_test2,y_train2,y_test2 = train_test_split(data_x_2, y_train, test_size = 0.2, random_state = 4)\n",
    "\n",
    "    #Create, fit, and evaluate quadradic model\n",
    "    quad_mod = linear_model.LinearRegression()\n",
    "    quad_mod.fit(x_train2, y_train2)\n",
    "    preds = quad_mod.predict(x_test2)\n",
    "\n",
    "    # Look at the actual vs. predicted values:\n",
    "    print(pd.DataFrame({'Actual': y_test2, 'Predicted': preds}).head(5))\n",
    "\n",
    "    # Look at the error metrics:\n",
    "    print('With Degree=',i)\n",
    "    print('Mean Squared Error, \\n' + str(mean_squared_error(y_test2,preds)) + '\\n' +\n",
    "                                       'R^2 \\n'+ str(r2_score(y_test2,preds)) + '\\n' +\n",
    "                                      'Median Absolute Error \\n' + str(median_absolute_error(y_test2,preds)) + '\\n' +\n",
    "                                      'Expected Variance Explained: \\n' + str(explained_variance_score(y_test2,preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Actual  Predicted\n",
      "107813      88  88.605932\n",
      "2172        90  88.613084\n",
      "65831       86  87.143046\n",
      "115828      87  86.368608\n",
      "102028      86  87.007571\n",
      "With Degree= 1\n",
      "Mean Squared Error, \n",
      "4.811918817016197\n",
      "R^2 \n",
      "0.46316379813802633\n",
      "Median Absolute Error \n",
      "1.5044164622333227\n",
      "Expected Variance Explained: \n",
      "0.463370408330084\n",
      "        Actual  Predicted\n",
      "107813      88  88.200603\n",
      "2172        90  89.253178\n",
      "65831       86  86.629925\n",
      "115828      87  86.182856\n",
      "102028      86  86.940872\n",
      "With Degree= 2\n",
      "Mean Squared Error, \n",
      "4.3398024242813955\n",
      "R^2 \n",
      "0.5158349218104092\n",
      "Median Absolute Error \n",
      "1.4536091386854082\n",
      "Expected Variance Explained: \n",
      "0.5161060460423037\n",
      "        Actual  Predicted\n",
      "107813      88  88.208834\n",
      "2172        90  89.797836\n",
      "65831       86  86.463853\n",
      "115828      87  86.035168\n",
      "102028      86  87.153470\n",
      "With Degree= 3\n",
      "Mean Squared Error, \n",
      "8.278331508433803\n",
      "R^2 \n",
      "0.07643744341106029\n",
      "Median Absolute Error \n",
      "1.421555067648697\n",
      "Expected Variance Explained: \n",
      "0.07643781887268253\n"
     ]
    }
   ],
   "source": [
    "# Check if Quadradic models work any better. The Model with degree 2 performed better.\n",
    "degree = [1,2,3]\n",
    "for i in degree:\n",
    "    # Create a quadratic variable preprocessor\n",
    "    quad = PolynomialFeatures(degree = i)\n",
    "    # Fit and transform the data\n",
    "    data_x_2 = quad.fit_transform(x_train[correlated_values])\n",
    "\n",
    "    x_train2,x_test2,y_train2,y_test2 = train_test_split(data_x_2, y_train, test_size = 0.2, random_state = 4)\n",
    "\n",
    "    #Create, fit, and evaluate quadradic model\n",
    "    quad_mod = linear_model.LinearRegression()\n",
    "    quad_mod.fit(x_train2, y_train2)\n",
    "    preds = quad_mod.predict(x_test2)\n",
    "\n",
    "    # Look at the actual vs. predicted values:\n",
    "    print(pd.DataFrame({'Actual': y_test2, 'Predicted': preds}).head(5))\n",
    "\n",
    "    # Look at the error metrics:\n",
    "    print('With Degree=',i)\n",
    "    print('Mean Squared Error, \\n' + str(mean_squared_error(y_test2,preds)) + '\\n' +\n",
    "                                       'R^2 \\n'+ str(r2_score(y_test2,preds)) + '\\n' +\n",
    "                                      'Median Absolute Error \\n' + str(median_absolute_error(y_test2,preds)) + '\\n' +\n",
    "                                      'Expected Variance Explained: \\n' + str(explained_variance_score(y_test2,preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing these results \n",
    "Comparing the model against the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Actual  Predicted\n",
      "124861      88  87.996376\n",
      "12566       87  88.389977\n",
      "122629      83  83.452636\n",
      "129224      86  86.619013\n",
      "92659       88  87.129701\n",
      "Mean Squared Error, \n",
      "4.28397870193224\n",
      "R^2 \n",
      "0.5151282648791193\n",
      "Median Absolute Error \n",
      "1.3827326230444612\n",
      "Expected Variance Explained: \n",
      "0.5153940228563683\n"
     ]
    }
   ],
   "source": [
    "# Create a quadratic variable preprocessor\n",
    "quad = PolynomialFeatures(degree = 2)\n",
    "# Fit and transform the data\n",
    "data_xtrain = quad.fit_transform(x_train[correlated_values])\n",
    "#data_ytrain = quad.transform(y_train)\n",
    "\n",
    "data_xtest = quad.transform(x_test1[correlated_values])\n",
    "#data_ytest = quad.transform(y_train)\n",
    "\n",
    "#Create, fit, and evaluate quadradic model\n",
    "quad_mod = linear_model.LinearRegression()\n",
    "quad_mod.fit(data_xtrain, y_train)\n",
    "preds = quad_mod.predict(data_xtest)\n",
    "\n",
    "# Look at the actual vs. predicted values:\n",
    "print(pd.DataFrame({'Actual': y_test1, 'Predicted': preds}).head(5))\n",
    "\n",
    "# Look at the error metrics:\n",
    "print('Mean Squared Error, \\n' + str(mean_squared_error(y_test1,preds)) + '\\n' +\n",
    "                                       'R^2 \\n'+ str(r2_score(y_test1,preds)) + '\\n' +\n",
    "                                      'Median Absolute Error \\n' + str(median_absolute_error(y_test1,preds)) + '\\n' +\n",
    "                                      'Expected Variance Explained: \\n' + str(explained_variance_score(y_test1,preds)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Wine Quality Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "numData = pd.read_csv('winequality.csv')\n",
    "numData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "I changed the white and red lables to 0 and 1 and since the 'good' column is directly correlated with the quality I dropped that variable. Then I notriced that some of the vairiables had a much larger range than others so I standardized them using standardscaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5ea1dd0c96e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Editing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Replace 'Red' with 1 and 'white' with 0 so all the variables are numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnumData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnumData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numData' is not defined"
     ]
    }
   ],
   "source": [
    "#Editing data\n",
    "# Replace 'Red' with 1 and 'white' with 0 so all the variables are numeric\n",
    "numData = numData.replace(to_replace= 'white', value= 0)\n",
    "numData = numData.replace(to_replace= 'red', value= 1)\n",
    "\n",
    "#split the data into test and training sets\n",
    "features = list(numData)\n",
    "features.remove('quality')\n",
    "features.remove('good')\n",
    "data_x = numData[features]\n",
    "data_y = numData['quality']\n",
    "\n",
    "#Create a Do not touch testing set\n",
    "x_train, x_test1, y_train, y_test1 = train_test_split(data_x, data_y, test_size = 0.2, random_state=4)\n",
    "\n",
    "#Standardize data\n",
    "# Convert all data so it is in a scale from 0 to 1\n",
    "standardscaler = preprocessing.StandardScaler()\n",
    "x_train = standardscaler.fit_transform(x_train)\n",
    "x_test1 = standardscaler.transform(x_test1)\n",
    "\n",
    "#Create a training and test set to pick models on\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a pairs plot tp see portential relationships\n",
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "sm = pd.plotting.scatter_matrix(numData[['fixed acidity',\n",
    " 'volatile acidity',\n",
    " 'citric acid',\n",
    " 'residual sugar',\n",
    " 'chlorides',\n",
    " 'free sulfur dioxide',\n",
    " 'quality',\n",
    " 'good',\n",
    " 'color']], diagonal = \"kde\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "sm = pd.plotting.scatter_matrix(numData[['total sulfur dioxide',\n",
    "'density',\n",
    " 'pH',\n",
    " 'sulphates',\n",
    " 'alcohol',\n",
    " 'quality',\n",
    " 'good',\n",
    " 'color']], diagonal = \"kde\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model\n",
    "already we can see that the model is performing better compared to the models created with the wine review data. However, the best R squared is only about 0.33 which is not ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Linear Model Does not perform well at any degree\n",
    "\n",
    "# construct model object\n",
    "model = linear_model.LinearRegression() \n",
    "model.fit(x_train,y_train) # Fit the model\n",
    "preds = model.predict(x_test) #Build predictions on the test data\n",
    "\n",
    "# Look at the actual vs. predicted values:\n",
    "print(pd.DataFrame({'Actual': y_test, 'Predicted': preds}).head(10))\n",
    "\n",
    "# Look at the error metrics:\n",
    "print('Mean Squared Error, Median Absolute Error, R^2, Expected Variance Explained: \\n' + \n",
    "                                                              str([mean_squared_error(y_test,preds), \n",
    "                                                            median_absolute_error(y_test,preds),\n",
    "                                                           r2_score(y_test,preds), explained_variance_score(y_test,preds)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Quadradic models didn't work any better\n",
    "degree = [1,2,3]\n",
    "for i in degree:\n",
    "    # Create a quadratic variable preprocessor\n",
    "    quad = PolynomialFeatures(degree = i)\n",
    "    # Fit and transform the data\n",
    "    data_x_2 = quad.fit_transform(data_x)\n",
    "\n",
    "    x_train2,x_test2,y_train2,y_test2 = train_test_split(data_x_2, data_y, test_size = 0.2, random_state = 4)\n",
    "\n",
    "    #Create, fit, and evaluate quadradic model\n",
    "    quad_mod = linear_model.LinearRegression()\n",
    "    quad_mod.fit(x_train2, y_train2)\n",
    "    preds = quad_mod.predict(x_test2)\n",
    "\n",
    "    # Look at the actual vs. predicted values:\n",
    "   # print(pd.DataFrame({'Actual': y_test, 'Predicted': preds}).head(10))\n",
    "\n",
    "    # Look at the error metrics:\n",
    "    print('With Degree=',i)\n",
    "    print('Mean Squared Error, Median Absolute Error, R^2, Expected Variance Explained: \\n' + \n",
    "                                                              str([mean_squared_error(y_test2,preds), \n",
    "                                                            median_absolute_error(y_test2,preds),\n",
    "                                                           r2_score(y_test2,preds), \n",
    "                                                                   explained_variance_score(y_test2,preds)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "This model performed much better than the linear regression. I think that the best model is when k = 3 because the accuracy is relatively large and compared to the other k-values that produce a higher accuracy this one is significantly smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Knn Isn't performing Very Well\n",
    "from sklearn import neighbors\n",
    "\n",
    "#Trying KNN Algorithm\n",
    "ks = [3, 5, 7, 9, 11, 13, 15, 17, 19] #Using odd numbers to make sure it doesn't end in a tie\n",
    "for k in ks:\n",
    "    # Create model and fit.\n",
    "    mod = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
    "    mod.fit(x_train, y_train)\n",
    "    \n",
    "    #Made predictions and look at results.\n",
    "    y_hat = mod.predict(x_test)\n",
    "    if accuracy_score(y_test, y_hat) > .57:\n",
    "        print('---------- EVALUATING MODEL: k = ' + str(k) + '----------')\n",
    "        print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "        #print('Precision: ' + str(precision_score(y_test, y_hat)))\n",
    "        #print('Recall: ' + str(recall_score(y_test, y_hat)))\n",
    "        #print('F1: ' + str(f1_score(y_test, y_hat)))\n",
    "        #print('ROC AUC: ' + str(roc_auc_score(y_test, y_hat)))\n",
    "        print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "This model performed worse than the Knn model with an accuracy of 0.467."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "nb = naive_bayes.BernoulliNB()\n",
    "#nb = naive_bayes.GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_hat = nb.predict(x_test)\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "This model performed best overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try Random Forrest. This performed better overall but it wasn't the most reliable model.\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Builds a sequence of Random Forest models for different n_est and depth values\n",
    "n_ests = [5, 10, 50, 80]\n",
    "depths = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "# Creates a list of tuples containing the n-est and depth values that perform well (n-est, depth)\n",
    "good_forest = []\n",
    "\n",
    "for n in n_ests:\n",
    "    for dp in depths:\n",
    "        mod = ensemble.RandomForestClassifier(n_estimators = n, max_depth = dp)\n",
    "        mod.fit(x_train, y_train)\n",
    "        y_hat = mod.predict(x_test)\n",
    "        good_forest.append((n, dp))\n",
    "        if accuracy_score(y_test, y_hat) > .64:\n",
    "            print('------ Evaluating model: n_estimators =' + str(n) + ', max_depth = ' + str(dp),'------')\n",
    "            print('Accuracy: ' + str(accuracy_score(y_test, y_hat)))\n",
    "            print('Confusion Matric: \\n' + str(confusion_matrix(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing these results\n",
    "Random Forest with 50 estimators and a max depth of 12 was the best but that isn't saying much when the accuracy is less than 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensemble' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a6d2487515a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrf_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------- Evaluating Random Forest Model ----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ensemble' is not defined"
     ]
    }
   ],
   "source": [
    "rf_mod = ensemble.RandomForestClassifier(n_estimators = 50, max_depth = 12)\n",
    "rf_mod.fit(x_train, y_train)\n",
    "y_hat = rf_mod.predict(x_test1)\n",
    "\n",
    "print('---------- Evaluating Random Forest Model ----------')\n",
    "print('Accuracy: ' + str(accuracy_score(y_test1, y_hat)))\n",
    "print('Confusion Matric: \\n' + str(confusion_matrix(y_test1, y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_mod = ensemble.RandomForestClassifier(n_estimators = 80, max_depth = 12)\n",
    "rf_mod.fit(x_train, y_train)\n",
    "y_hat = rf_mod.predict(x_test1)\n",
    "\n",
    "print('---------- Evaluating Random Forest Model ----------')\n",
    "print('Accuracy: ' + str(accuracy_score(y_test1, y_hat)))\n",
    "print('Confusion Matric: \\n' + str(confusion_matrix(y_test1, y_hat)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
